\chapter{Endpoint node}
\label{chap:endpoint}

Endpoint is a device that acts as an interface between sensor node network and external clients and services. This chapter focuses on the embedded system implementation, on how communication with nodes has been implemented and then on data acquisition process.


\section{System setup}

For an endpoint Intel Edison \ac{COM} was used. It runs x86 instruction set\cite{Edison} which should allow for compatibility with most of the embedded operating systems. Unfortunately, it has a custom architecture with integrated Intel Quark microcontroller as a coprocessor which most of the standard operating systems don't support. Intel in its \ac{BSP} provides a Yocto Linux image and compilation tools\cite{yocto}. For an easy setup, already compiled system images are available. Although Yocto is relatively easy to use, it requires an image to be compiled and uploaded for every change. This takes a lot of time in development process. Prebuilt system image provides most of the features needed by this project but it doesn't have a \ac{HTTP} server such as Nginx or Apache2. Instead, most of Edison projects are running \ac{HTTP} server inbuilt into NodeJS. This usually works just fine with simple applications providing data to 1 client. But if data is to be accessed by multiple clients, client requests are queued and served by a single core. Also, if the server crashes, there is no automatic restart or repair features. That's why port of Debian Linux distribution called Ubilinux was used in this project\cite{ubilinux}. For an \ac{HTTP} server Nginx was used\cite{nginx}. It was configured to monitor and automatically restart the application if it crashes. Another feature that nginx provides is automatic serving and caching of static files. Server was instructed to serve all javascript, css files and images directly from file system. Another feature that Nginx allows is logging so access and server log hold the data on the server usage.

One of currently most popular programming languages is Python. It is a scripting language which supports object oriented programming and has some functional programming features. There are multiple frameworks designed to allow Python users to serve web pages. Most popular ones are Django, Pyramid and Flask. Django is a big framework which is very structured and pragmatical which is a very good feature for big projects but doesn't work well for smaller ones. Pyramid on the other hand is very customizable but requires a lot of configuration to work as intended. Flask is actually a microframework which urges users to follow good design practices but does not require a lot of configuration or boiler-plate tasks to be done. Also, it is very easy to learn and use so it was a framework of choice for this project\cite{flask}. Web pages and services programmed in Flask are usually served by uwsgi server application. uwsgi was configured in such a way that it serves data to Nginx through Linux socket which then serves web pages and content to the end user.

Since endpoint is also used for data accumulation, a data is stored in database. Database of choice for this project is PostgreSQL\cite{postgres}. To allow easier communication with database a SQLAlchemy \ac{ORM} toolkit was used. It allowed direct mapping of Python classes to ER modelled database tables. It removed the need to write SQL code in the application. Instead of that, a session is created which is then queried for data which allows easy adding, update and delete of database rows. When a database model is developed for the first time, a table can be created. But when a new column needs to be added to the table, it's quite impractical to delete table and create a new one manually. This is why Flask package flask-migrate is providing possibility of automatic database initialization and when changes to the model are done it can be run to generate migration scripts and upgrade the database. To start nginx, postgres and uwsgi systemd scripts are used. Postgres and nginx scripts were provided with the respected packages but a custom script had to be written for uwsgi. The script creates the directory for socket file and starts the application. A detailed description how to set the project up is available on project \href{github.com/Xenosb/thesis-edison}{GitHub} page.


\section{Communication with sensor network}

From endpoints perspective, communication with sensor network relies on Intel's mraa library\cite{mraa}. Library allows for an easy access to hardware features such as \ac{GPIO}, \ac{I2C}, \ac{USART} and \ac{SPI} on GNU/Linux systems. Library detects the platform on which it is deployed in runtime and by doing so makes the same code run on all supported platforms. Some of the supported boards are Intel Galileo, Intel Edison, Intel Joule, Raspberry Pi, Beaglebone Black and even Terasic DE10-Nano \ac{FPGA}. Library also provides \ac{API}s for multiple programming languages - C++, Python, Java and NodeJS. Intel Edison has 2 available I2C interfaces - I2C1 and I2C6. To communicate with the nodes an IO expansion shield was used which exposed I2C6 pins as only \ac{I2C} interface\cite{ioexpansion}. First, a board was connected to node and a script was run to test \ac{I2C} functionality. This didn't work and node was unable to read any packages sent from the endpoint. A logic analyzer was connected to the bus and what was seen was that data signals were raised before the appropriate clock signals. This caused the packets to be unreadable. To fix this, another expansion board which provided access to I2C port 1 was used. After plugging in the Edison module and running the script everything was working. The difference between I2C1 and I2C6 can be seen in Figure \ref{fig:endpoint_i2c16}.

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=0.8\linewidth]{3-edison_i2c6.png}
    \includegraphics[width=0.8\linewidth]{3-edison_i2c1.png}
  \end{center}
  \caption{I2C port 6 exposed on custom expansion board not working.}
  \label{fig:endpoint_i2c16}
\end{figure}

After \ac{I2C} communication was working, additional wire for position sensing was connected to the pin 31. This pin is labeled as GPIO-44 on Intel Edison. To distribute \ac{I2C} addresses to the sensor node network first a general call is issued by addressing 0x00. To reset node addresses, 0x55 is sent. All of the listening nodes switch their address to a default value of 0x55 and set their position sensing pin output to low. After that, endpoint rises its position sensing pin to high and writes 0x11 into register 0xfa of address 0x55. Node which is directly connected to the endpoint will have its position sensing pin input set to high and will set its address to 0x11. To confirm that address was successfully set, endpoint reads from register 0xfa of address 0x11. If it receives 0x11 as an answer, address was successfully set and endpoint will issue a command that will pull the position sensing pin down. Then, it will write 0x01 to register 0xf0 of the node 0x11 which means that addressed node has to set its position sensing output pin high. After that endpoint does the same procedure for the next node increasing the number of the issued address. An edge condition is recognized by node not responding to read of its address. For example, if node 7 doesn't exist, reading from register 0xfa of address 0x17 won't return anything. Endpoint has a timeout and will detect that and set the position sensing output of the last addressed node back to low. The whole process can be seen in Figure \ref{fig:endpoint_sequence}.

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=\linewidth]{3-edison_sequence.png}
  \end{center}
  \caption{Sequence diagram showing process of address renewal for 2 nodes.}
  \label{fig:endpoint_sequence}
\end{figure}


\section{Data acquisition routine}

For the system to function as described, both data acquisition process and web server have to run in parallel and without concurrency issues. Sensor network data is shared through the database and this doesn't cause concurrency issues because data acquisition routine is constantly adding new data while web server is only reading or modifying already stored data. But some things like acquisition start and stop or \ac{I2C} address redistribution commanding are a part of control logic which doesn't have to be stored in the database. In fact, implementation of communication between two separate processes using database would be quite inefficient. This is why a system pipe is used for message communication. Starting and stopping the data acquisition routine, changing between simulation and sensor network data collection and \ac{I2C} address redistribution are implemented using pipe communication. Pipe has two ends - data acquisition has one end and web server has the other. When a process is reading or writing data to a pipe, it uses a pipe end provided to it. This makes communication between processes easy and robust. Data acquisition process also uses an activity flag which is set when process is collecting data. This flag is used by web server to check if there is a need to read new data from the database and to decide if it is possible to start or stop the routine. This flag is implemented as a shared memory object. Both pipe and shared memory are created when uwsgi starts the application.

First thing data acquisition does when it's instantiated is read the system configuration. Configuration file defines 3 different scenarios - production environment on Intel Edison, testing environment on Intel Edison and testing environment on development \ac{PC}. Configurations are implemented as classes extending the same parent class which is holding shared configuration settings such as web application secret and update frequency. Extending configurations hold information on database \ac{URI}, debug properties and deployment environment. Then, according to the configuration \ac{URI}, data acquisition routine acquires connection to the database and depending on the configuration sets the data read function to point to read function from nodes or from a simulator. It isn't possible to always get the data from the sensor nodes. Such case would be development of frontend or backend software on an external \ac{PC}. This is why simulator was implemented to randomly generate sensor node data.

The database has 3 tables for storing the sensor network data. First there is a \code{Node} class. Each node has its unique \ac{id} but is also described by its position (eg. 1 for node covering pillow and shoulder region, 2 for node covering chest). Second model is \code{Sensor} and it holds information on each of the \ac{FSR} sensors. Each sensor has a single node which it references but node can also access aggregated sensors as an array with the help of SQLAlchemy's backreference feature. To know which sensor is which, sensor table also holds information on sensors position (eg. sensor 1 is the one closest to the left bed frame side). When a reading from sensor is taken, it is saved as an instance of \code{SensorValue} model. This table holds the timestamp and value as well as a reference to which sensor this sensor reading belongs to. For each of the models, two additional methods are implemented. \code{{\_\_}repr{\_\_}()} method is used for easier debug reading and \code{serialize()} is used for object representation as JSON. An \ac{ER} model can be seen in Figure \ref{fig:endpoint_classes}. \\

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=0.7\linewidth]{3-endpoint_classes.png}
  \end{center}
  \caption{Database \ac{ER} model for storing sensor values and system information.}
  \label{fig:endpoint_classes}
\end{figure}

So how does the system acquire sensor data from the nodes? Process first checks for data in the pipe. If start, stop or address redistribution command is received it will accordingly change its activity state or execute the redistribution procedure. Then, depending on the specified platform - edison or \ac{PC} it will execute a sensor readout method. Simulation method queries all available sensors and generates new sensor value. After that sensor value object, sensor and node are added to session and session is synchronized so that data is written to the database. For actual sensor readout on Edison, a method involves reading from every sensor on every available node. Problem with mraa implementation on Edison is that it doesn't set the acknowledge bit after it receives data from the node. This locks the node and it can't process another read request if a new byte is sent by master. This is why before the read request, a write request is issued. After that, a request for specified sensor is issued. Since sensor reads maximum voltage when there is no pressure, value is inverted by subtracting current sensor value from maximal value. As read error encountered on the \ac{I2C} bus is the same as maximum voltage, reading procedure is retried multiple times until value is over threshold. To prevent program locking in this state, number of retries is limited. After reading was taken it's saved to the database. After all sensors were updated, process sleeps for a period defined in configuration file. Program flow is shown as a graph in Figure \ref{fig:endpoint_logic}.

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=\linewidth]{3-endpoint_logic.png}
  \end{center}
  \caption{Flow diagram of data acquisition process.}
  \label{fig:endpoint_logic}
\end{figure}